{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "897d79c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.io import loadmat\n",
    "from time import perf_counter as timer\n",
    "\n",
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f89ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "thermal = Thermal()\n",
    "renewable = Renewable()\n",
    "demand = Demand()\n",
    "commitment = Commitment()\n",
    "data = Data()\n",
    "\n",
    "data.load_thermal(thermal)\n",
    "data.load_renewable_capacity(renewable)\n",
    "data.load_renewable_generation(renewable)\n",
    "data.load_demand(demand)\n",
    "data.load_commitment_decision(commitment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0be3085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Results:\n",
    "    def __init__(self):\n",
    "        self.objval = []\n",
    "        self.smp = []\n",
    "        self.slack = []\n",
    "        self.offunit_bool = []\n",
    "        self.runtime = []\n",
    "        self.total_runtime = []\n",
    "\n",
    "    def collect(self, objval, smp, slack, offunit_bool, runtime, total_runtime):\n",
    "        self.objval.append(objval)\n",
    "        self.smp.append(smp)\n",
    "        self.slack.append(slack)\n",
    "        self.offunit_bool.append(offunit_bool)\n",
    "        self.runtime.append(runtime)\n",
    "        self.total_runtime.append(total_runtime)\n",
    "\n",
    "\n",
    "    def convert_list_to_nparray(self):\n",
    "        self.objval = np.array(self.objval)\n",
    "        self.smp = np.array(self.smp)\n",
    "        self.slack = np.array(self.slack)\n",
    "        self.offunit_bool = np.array(self.offunit_bool)\n",
    "        self.runtime = np.array(self.runtime)\n",
    "        self.total_runtime = np.array(self.total_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1081a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ecf2ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8760, 197)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "renewable.solar_generation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3a8d72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_hour = 0\n",
    "\n",
    "model = gp.Model()\n",
    "\n",
    "hourly_decision = commitment.decision[idx_hour]\n",
    "\n",
    "\n",
    "p_thermal = model.addVars(\n",
    "    thermal.count,\n",
    "    lb=(thermal.pmin * hourly_decision).tolist(),\n",
    "    ub=(thermal.pmax * hourly_decision).tolist(),\n",
    ")\n",
    "\n",
    "p_solar = model.addVars(renewable.count, lb=0, ub=renewable.solar_generation[idx_hour].tolist())\n",
    "p_wind = model.addVars(renewable.count, lb=0, ub=renewable.wind_generation[idx_hour].tolist())\n",
    "p_hydro = model.addVars(renewable.count, lb=0, ub=renewable.hydro_generation[idx_hour].tolist())\n",
    "\n",
    "sum_p_thermal =  gp.quicksum(p_thermal[g] for g in range(thermal.count))\n",
    "sum_p_solar = gp.quicksum(p_solar[b] for b in range(renewable.count))\n",
    "sum_p_wind = gp.quicksum(p_wind[b] for b in range(renewable.count))\n",
    "sum_p_hydro = gp.quicksum(p_hydro[b] for b in range(renewable.count))\n",
    "\n",
    "model.addConstr(sum_p_thermal + sum_p_solar + sum_p_wind + sum_p_hydro == demand.total[idx_hour])\n",
    "\n",
    "total_cost_thermal = gp.quicksum(\n",
    "    thermal.c2.tolist()[g] * p_thermal[g] * p_thermal[g] + thermal.c1.tolist()[g] * p_thermal[g] + (thermal.c0.tolist() * hourly_decision).tolist()[g]\n",
    "    for g in range(thermal.count)\n",
    ")\n",
    "\n",
    "model.setObjective(total_cost_thermal, gp.GRB.MINIMIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3842b8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "GurobiError",
     "evalue": "Model too large for size-limited license; visit https://gurobi.com/unrestricted for more information",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGurobiError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39msetParam(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutputFlag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32msrc/gurobipy/_model.pyx:903\u001b[0m, in \u001b[0;36mgurobipy._model.Model.optimize\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mGurobiError\u001b[0m: Model too large for size-limited license; visit https://gurobi.com/unrestricted for more information"
     ]
    }
   ],
   "source": [
    "model.setParam(\"OutputFlag\", 0)\n",
    "model.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfe0455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1220e2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa7ba77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f9feee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63393c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b36fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_hour in range(8760):\n",
    "    timer_start = timer()\n",
    "    model = gp.Model()\n",
    "\n",
    "    p = model.addVars(\n",
    "        thermal.count,\n",
    "        lb=(thermal.pmin * commitment.decision[idx_hour]).tolist(),\n",
    "        ub=(thermal.pmax * commitment.decision[idx_hour]).tolist(),\n",
    "    )\n",
    "\n",
    "    model.addConstr(\n",
    "        gp.quicksum(p[g] for g in range(thermal.count)) == \n",
    "        demand.total[idx_hour] - renewable.total_generation[idx_hour],\n",
    "    )\n",
    "\n",
    "    model.setObjective(\n",
    "        gp.quicksum(\n",
    "            thermal.c2.tolist()[g] * p[g] * p[g] + thermal.c1.tolist()[g] * p[g] + (thermal.c0 * commitment.decision[idx_hour]).tolist()[g]\n",
    "            for g in range(thermal.count)\n",
    "        ),\n",
    "        gp.GRB.MINIMIZE\n",
    "    )\n",
    "\n",
    "    model.setParam(\"OutputFlag\", 0)\n",
    "    model.optimize()\n",
    "    timer_end = timer()\n",
    "\n",
    "    if model.Status == gp.GRB.OPTIMAL:\n",
    "        objval = model.ObjVal\n",
    "        smp = model.getAttr(\"Pi\")[0]\n",
    "        slack = model.getAttr(\"Slack\")[0]\n",
    "        offunit_bool = np.all(np.array(model.getAttr(\"X\"))[np.where(1 - commitment.decision[idx_hour])[0]] == 0)\n",
    "        runtime = model.Runtime\n",
    "        total_runtime = timer_end - timer_start\n",
    "\n",
    "        results.collect(objval, smp, slack, offunit_bool, runtime, total_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dbcea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.convert_list_to_nparray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d997dfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(results.offunit_bool), results.slack.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1103939",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.runtime.mean(), (results.total_runtime - results.runtime).mean(), results.total_runtime.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2698f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_hour in range(8760):\n",
    "    timer_start = timer()\n",
    "    model = gp.Model()\n",
    "\n",
    "    p = model.addVars(\n",
    "        thermal.count,\n",
    "        lb=(thermal.pmin * commitment.decision[idx_hour]).tolist(),\n",
    "        ub=(thermal.pmax * commitment.decision[idx_hour]).tolist(),\n",
    "    )\n",
    "\n",
    "    model.addConstr(\n",
    "        gp.quicksum(p[g] for g in range(thermal.count)) == \n",
    "        demand.total[idx_hour] - renewable.total_generation[idx_hour],\n",
    "    )\n",
    "\n",
    "    model.setObjective(\n",
    "        gp.quicksum(\n",
    "            thermal.c2[g].tolist() * p[g] * p[g] + thermal.c1[g].tolist() * p[g]\n",
    "            for g in range(thermal.count)\n",
    "        ),\n",
    "        gp.GRB.MINIMIZE\n",
    "    )\n",
    "\n",
    "    model.setParam(\"OutputFlag\", 0)\n",
    "    model.optimize()\n",
    "    timer_end = timer()\n",
    "\n",
    "    if model.Status == gp.GRB.OPTIMAL:\n",
    "        objval = model.ObjVal\n",
    "        smp = model.getAttr(\"Pi\")[0]\n",
    "        slack = model.getAttr(\"Slack\")[0]\n",
    "        offunit_bool = np.all(np.array(model.getAttr(\"X\"))[np.where(1 - commitment.decision[idx_hour])[0]] == 0)\n",
    "        runtime = model.Runtime\n",
    "        total_runtime = timer_end - timer_start\n",
    "\n",
    "        results.collect(objval, smp, slack, offunit_bool, runtime, total_runtime)\n",
    "\n",
    "    # elif model.Status == gp.GRB.INFEASIBLE:\n",
    "    #     model.computeIIS()\n",
    "    #     checker = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db576a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # if model.Status == gp.GRB.OPTIMAL:\n",
    "    #     result_smp.append(model.getAttr(\"Pi\", model.getConstrs())[0])\n",
    "    #     result_noncommitp0true.append(np.all(np.array(model.getAttr(\"X\", p.values()))[np.where(commitment.decision[idx_hour] == 0)[0]] == 0))\n",
    "    #     result_slack.append(model.getAttr(\"Slack\", model.getConstrs())[0])\n",
    "    #     result_runtime.append(model.Runtime)\n",
    "\n",
    "    # elif model.Status == gp.GRB.INFEASIBLE:\n",
    "    #     model.computeIIS()\n",
    "    #     iis_char = \"n\"\n",
    "    #     yeah = model.getVars()[0]\n",
    "    #     if yeah.IISUB:\n",
    "    #         iis_char = \"u\"\n",
    "    #     elif yeah.IISLB:\n",
    "    #         iis_char = \"l\"\n",
    "    #     result_infeasible.append(iis_char)\n",
    "\n",
    "    # else:\n",
    "    #     raise ValueError(\"wtf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9728df65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccaf29d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
